{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_parquet('becode_file.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop features that are irrelevant or unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['last_redeem_date', 'forelast_switch_dte', 'survey_interaction_type', 'nps_score',\n",
    "                   'contr_nr', 'dim_cust_nr','wifi_days_used', 'wifi_weighted_drops', 'wifi_n_devices',\n",
    "                   'wifi_total_traffic', 'wifi_n_sessions_t5', 'wifi_total_pings_t5', 'wifi_total_active_pings_t5',\n",
    "                   'wifi_mean_active_connduration_t5', 'wifi_total_traffic_t5', 'wifi_total_retransmitted_traffic_t5',\n",
    "                   'wifi_mean_active_deff_t5', 'wifi_std_active_deff_t5', 'wifi_active_deff_score_t5',\n",
    "                    'todt_rono_roof_avg3m_vol', 'tovc_rono_roof_avg3m_dur', 'tosm_rono_roof_avg3m_evt',\n",
    "                    'todt_rono_roof_vol', 'tovc_rono_roof_dur', 'tosm_rono_roof_evt', 'pre_days_since_last_reload',\n",
    "                    'pre_most_frequent_amt', 'pre_count_tot_rel', 'net_total_paging_attempts', 'net_total_call_attempts',\n",
    "                    'post_remaining_loyalty_days', 'mob_mobility', 'mob_variance_in_mobility', 'post_device_chg_days',\n",
    "                    'post_contr_oob_m1_rev', 'post_contr_oob_m2_rev', 'post_contr_oob_m3_rev', 'post_tdt_rev',\n",
    "                    'post_tvc_rev', 'installation_days', 'move_days', 'mesh_wifi', 'internet_boost', 'extra_decoder',\n",
    "                    'chromecast', 'foot_option', 'mobile_insurance', 'cable_easy_switch_origin', 'tv_decoder_type',\n",
    "                    'tot_nbr_subsidy', 'tot_nbr_instalment', 'post_dunning_last_hope_1m', 'post_dunning_reminder1_1m',\n",
    "                    'post_dunning_reminder2_1m', 'post_dunning_reminder3_1m', 'post_dunning_reminder4_1m', 'highest_reup',\n",
    "                    'lowest_reup', 'latest_reup', 'highest_upfront', 'lowest_upfront', 'latest_upfront', 'months_since_latest_subsidy_start',\n",
    "                    'months_since_latest_instal_start', 'nbr_sub_inst_iphones', 'nbr_sub_inst_samsung', 'nbr_sub_inst_other_brands',\n",
    "                    'sub_inst_latest_device_brand', 'convergence_tenure', 'handset_model_ten_yr_at_chng', 'days_since_post_latest',\n",
    "                    'days_since_pre_latest', 'operator_switch_cnt_y', 'home_int_from_start'\n",
    "                    ]\n",
    "len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_less = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding or categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "categorical_columns = df_less.select_dtypes('object').columns\n",
    "df_less[categorical_columns] = encoder.fit_transform(df_less[categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_less), columns=df_less.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "scaled_data_array = sc.fit_transform(df_imputed)\n",
    "scaled_data = pd.DataFrame(scaled_data_array, columns = df_imputed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=500, n_components=15, verbose=True)\n",
    "embedding = reducer.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8)\n",
    "X = embedding\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(X)\n",
    "scaled_data['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Means comparison between clusters to extract the most important features for each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference between cluster zero and other clusters.\n",
    "cluster_zero = scaled_data[scaled_data['clusters'] == 0]\n",
    "all_minus_zero = scaled_data[scaled_data['clusters'] != 0]\n",
    "difference_zero = cluster_zero.mean().subtract(all_minus_zero.mean())\n",
    "# Set threshold to filter out non important features.\n",
    "filter_zero = difference_zero.loc[(difference_zero > 1.2) | (difference_zero < -1.2)]\n",
    "# Get list of important features for this cluster.\n",
    "scaled_data_zero = filter_zero.to_frame().transpose()\n",
    "columns_zero = scaled_data_zero.columns.values.tolist()\n",
    "\n",
    "# Repeat this for all the other clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_one = scaled_data[scaled_data['clusters'] == 1]\n",
    "all_minus_one = scaled_data[scaled_data['clusters'] != 1]\n",
    "difference_one = cluster_one.mean().subtract(all_minus_one.mean())\n",
    "filter_one =difference_one.loc[(difference_one > 1.0) | (difference_one < -1.0)]\n",
    "scaled_data_one = filter_one.to_frame().transpose()\n",
    "columns_one = scaled_data_one.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_two = scaled_data[scaled_data['clusters'] == 2]\n",
    "all_minus_two = scaled_data[scaled_data['clusters'] != 2]\n",
    "difference_two = cluster_two.mean().subtract(all_minus_two.mean())\n",
    "filter_two =difference_two.loc[(difference_two > 1.0) | (difference_two < -1.0)]\n",
    "scaled_data_two = filter_two.to_frame().transpose()\n",
    "columns_two = scaled_data_two.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_three = scaled_data[scaled_data['clusters'] == 3]\n",
    "all_minus_three = scaled_data[scaled_data['clusters'] != 3]\n",
    "difference_three = cluster_three.mean().subtract(all_minus_three.mean())\n",
    "filter_three =difference_three.loc[(difference_three > 1.1) | (difference_three < -1.0)]\n",
    "scaled_data_three = filter_three.to_frame().transpose()\n",
    "columns_three = scaled_data_three.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_four = scaled_data[scaled_data['clusters'] == 4]\n",
    "all_minus_four = scaled_data[scaled_data['clusters'] != 4]\n",
    "difference_four = cluster_four.mean().subtract(all_minus_four.mean())\n",
    "filter_four =difference_four.loc[(difference_four > 1.1) | (difference_four < -1.0)]\n",
    "scaled_data_four = filter_four.to_frame().transpose()\n",
    "columns_four = scaled_data_four.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_five = scaled_data[scaled_data['clusters'] == 5]\n",
    "all_minus_five = scaled_data[scaled_data['clusters'] != 5]\n",
    "difference_five = cluster_five.mean().subtract(all_minus_five.mean())\n",
    "filter_five =difference_five.loc[(difference_five > 1.) | (difference_five < -1.0)]\n",
    "scaled_data_five = filter_five.to_frame().transpose()\n",
    "columns_five = scaled_data_five.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_six = scaled_data[scaled_data['clusters'] == 6]\n",
    "all_minus_six = scaled_data[scaled_data['clusters'] != 6]\n",
    "difference_six = cluster_six.mean().subtract(all_minus_six.mean())\n",
    "filter_six =difference_six.loc[(difference_six > 1.) | (difference_six < -1.0)]\n",
    "scaled_data_six = filter_six.to_frame().transpose()\n",
    "columns_six = scaled_data_six.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_seven = scaled_data[scaled_data['clusters'] == 7]\n",
    "all_minus_seven = scaled_data[scaled_data['clusters'] != 7]\n",
    "difference_seven = cluster_seven.mean().subtract(all_minus_seven.mean())\n",
    "filter_seven =difference_seven.loc[(difference_seven > 1.1) | (difference_seven < -1.0)]\n",
    "scaled_data_seven = filter_seven.to_frame().transpose()\n",
    "columns_seven = scaled_data_seven.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of clusters in original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cluster = df[df['clusters'] == 0]\n",
    "# Filter only the important features for this cluster.\n",
    "zero_cluster = zero_cluster[columns_zero]\n",
    "# Output the precentage of the unique values for each feature in this cluster\n",
    "for c in zero_cluster.columns:\n",
    "    print(c)\n",
    "    print(zero_cluster[c].value_counts() / len(zero_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "# Output the precentage of the unique values for each feature for the other clusters\n",
    "print(\"other clusters\")\n",
    "zero_cluster = df[df['clusters'] != 0]\n",
    "zero_cluster = zero_cluster[columns_zero]\n",
    "for c in zero_cluster.columns:\n",
    "    print(c)\n",
    "    print(zero_cluster[c].value_counts() / len(zero_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "# Repeat this for all clusters.\n",
    "# Use these outputs to interpret the clusters.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cluster = df[df['clusters'] == 1]\n",
    "first_cluster = first_cluster[columns_one]\n",
    "for c in first_cluster.columns:\n",
    "    print(c)\n",
    "    print(first_cluster[c].value_counts() / len(first_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "first_cluster = df[df['clusters'] != 1]\n",
    "first_cluster = first_cluster[columns_one]\n",
    "for c in first_cluster.columns:\n",
    "    print(c)\n",
    "    print(first_cluster[c].value_counts() / len(first_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_cluster = df[df['clusters'] == 2]\n",
    "second_cluster = second_cluster[columns_two]\n",
    "for c in second_cluster.columns:\n",
    "    print(c)\n",
    "    print(second_cluster[c].value_counts() / len(second_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "second_cluster = df[df['clusters'] != 2]\n",
    "second_cluster = second_cluster[columns_two]\n",
    "for c in second_cluster.columns:\n",
    "    print(c)\n",
    "    print(second_cluster[c].value_counts() / len(second_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_cluster = df[df['clusters'] == 3]\n",
    "third_cluster = third_cluster[columns_three]\n",
    "for c in third_cluster.columns:\n",
    "    print(c)\n",
    "    print(third_cluster[c].value_counts() / len(third_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "third_cluster = df[df['clusters'] != 3]\n",
    "third_cluster = third_cluster[columns_three]\n",
    "for c in third_cluster.columns:\n",
    "    print(c)\n",
    "    print(third_cluster[c].value_counts() / len(third_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_cluster = df[df['clusters'] == 4]\n",
    "fourth_cluster = fourth_cluster[columns_four]\n",
    "for c in fourth_cluster.columns:\n",
    "    print(c)\n",
    "    print(fourth_cluster[c].value_counts() / len(fourth_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "fourth_cluster = df[df['clusters'] != 4]\n",
    "fourth_cluster = fourth_cluster[columns_four]\n",
    "for c in fourth_cluster.columns:\n",
    "    print(c)\n",
    "    print(fourth_cluster[c].value_counts() / len(fourth_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_cluster = df[df['clusters'] == 5]\n",
    "fifth_cluster = fifth_cluster[columns_five]\n",
    "for c in fifth_cluster.columns:\n",
    "    print(c)\n",
    "    print(fifth_cluster[c].value_counts() / len(fifth_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "fifth_cluster = df[df['clusters'] != 5]\n",
    "fifth_cluster = fifth_cluster[columns_five]\n",
    "for c in fifth_cluster.columns:\n",
    "    print(c)\n",
    "    print(fifth_cluster[c].value_counts() / len(fifth_cluster) * 100)\n",
    "    print(\"-----------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sixth_cluster = df[df['clusters'] == 6]\n",
    "sixth_cluster = sixth_cluster[columns_six]\n",
    "sixth_cluster.nunique()\n",
    "for c in sixth_cluster.columns:\n",
    "    print(c)\n",
    "    print(sixth_cluster[c].value_counts() / len(sixth_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "sixth_cluster = df[df['clusters'] != 6]\n",
    "sixth_cluster = sixth_cluster[columns_six]\n",
    "sixth_cluster.nunique()\n",
    "for c in sixth_cluster.columns:\n",
    "    print(c)\n",
    "    print(sixth_cluster[c].value_counts() / len(sixth_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seventh_cluster = df[df['clusters'] == 7]\n",
    "seventh_cluster = seventh_cluster[columns_seven]\n",
    "for c in seventh_cluster.columns:\n",
    "    print(c)\n",
    "    print(seventh_cluster[c].value_counts() / len(seventh_cluster) * 100)\n",
    "    print(\"-----------------\")\n",
    "print(\"################################################################\")\n",
    "print(\"other clusters\")\n",
    "seventh_cluster = df[df['clusters'] != 7]\n",
    "seventh_cluster = seventh_cluster[columns_seven]\n",
    "for c in seventh_cluster.columns:\n",
    "    print(c)\n",
    "    print(seventh_cluster[c].value_counts() / len(seventh_cluster) * 100)\n",
    "    print(\"-----------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
